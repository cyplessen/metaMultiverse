#' Run Multiverse Meta-Analysis
#'
#' Executes a comprehensive multiverse meta-analysis across all specifications,
#' applying different combinations of study selection criteria ("Which" factors),
#' meta-analytic methods, and dependency handling strategies.
#'
#' @param data A validated data frame containing the meta-analysis dataset.
#'   Must be previously validated using \code{\link{check_data_multiverse}}.
#'   Required columns: \code{study}, \code{es_id}, \code{yi}, \code{vi}, plus any
#'   "Which factor" columns (e.g., \code{wf_1}, \code{wf_2}).
#' @param specifications A data frame of analysis specifications generated by
#'   \code{\link{create_principled_multiverse_specifications}}. Each row represents
#'   one unique combination of Which factors, dependency handling, and meta-analytic method.
#' @param verbose Logical. If \code{TRUE}, prints detailed progress information
#'   and a summary of warnings at completion (default: \code{FALSE}).
#' @param progress Logical. If \code{TRUE}, displays a progress bar during execution
#'   (default: \code{TRUE}).
#'
#' @return An object of class \code{"multiverse_result"} containing:
#' \describe{
#'   \item{\code{results}}{A data frame with one row per successful analysis, including:
#'     \itemize{
#'       \item \code{b}: Effect size estimate
#'       \item \code{ci.lb}, \code{ci.ub}: 95% confidence interval bounds
#'       \item \code{pval}: P-value (NA for Bayesian methods)
#'       \item \code{k}: Number of studies included in the analysis
#'       \item \code{set}: Character string listing the study IDs included
#'       \item \code{full_set}: Binary indicator (1 = all studies included, 0 = subset)
#'       \item All "Which factor" columns from specifications
#'       \item \code{dependency}: Dependency handling method used
#'       \item \code{ma_method}: Meta-analytic method used
#'       \item \code{multiverse_id}: Groups specifications into separate multiverse analyses
#'     }
#'   }
#'   \item{\code{multiverse_warnings}}{Character vector of all warnings encountered}
#'   \item{\code{n_warnings}}{Integer count of total warnings}
#' }
#'
#' @section Workflow Overview:
#' The function executes the following steps:
#' \enumerate{
#'   \item \bold{Iterate through specifications}: Each row in \code{specifications}
#'         defines one unique analysis to perform
#'   \item \bold{Apply Which factors}: Filter studies based on specified criteria
#'         (e.g., only studies with certain populations, measures, etc.)
#'   \item \bold{Handle dependencies}: Apply appropriate dependency handling:
#'         \itemize{
#'           \item \code{"aggregate"}: Pool multiple effect sizes per study using
#'                 composite correlation structure
#'           \item \code{"select_max"}/\code{"select_min"}: Select one effect size
#'                 per study based on magnitude
#'           \item \code{"modeled"}: Use multilevel models (3-level, RVE) to
#'                 explicitly model dependency structure
#'         }
#'   \item \bold{Apply meta-analytic method}: Execute the specified estimator
#'         (FE, REML, bias-correction methods, etc.)
#'   \item \bold{Combine and clean results}: Merge all successful analyses,
#'         remove duplicates, and add summary indicators
#' }
#'
#' @section Error Handling:
#' The function is designed to be robust:
#' \itemize{
#'   \item Individual specification failures don't stop the entire analysis
#'   \item Warnings are captured and can be reviewed post-analysis
#'   \item Invalid combinations (e.g., wrong dependency for a method) return \code{universe_NA}
#'   \item Progress tracking helps identify where issues occur
#' }
#'
#' @section Performance Considerations:
#' For large multiverse analyses:
#' \itemize{
#'   \item Consider setting \code{progress = FALSE} for cleaner output in scripts
#'   \item The function uses vectorized operations where possible
#'   \item Memory usage scales with the number of successful specifications
#'   \item Use \code{options(metaMultiverse.skip_slow = TRUE)} to exclude
#'         computationally intensive methods like Bayesian estimators
#' }
#'
#' @examples
#' \dontrun{
#' # Step 1: Prepare and validate data
#' data <- data.frame(
#'   study = rep(paste0("Study_", 1:8), each = 2),
#'   es_id = 1:16,
#'   yi = rnorm(16, mean = 0.3, sd = 0.4),
#'   vi = runif(16, min = 0.01, max = 0.05),
#'   wf_population = rep(c("adults", "children"), times = 8),
#'   wf_measure = rep(c("self-report", "behavioral"), each = 8)
#' )
#' validated_data <- check_data_multiverse(data)
#'
#' # Step 2: Create specifications
#' decision_map <- c("wf_population" = "E", "wf_measure" = "U")
#' specs <- create_principled_multiverse_specifications(
#'   data = validated_data,
#'   wf_vars = c("wf_population", "wf_measure"),
#'   ma_methods = c("fe", "reml", "pet-peese"),
#'   dependencies = c("aggregate", "select_max"),
#'   decision_map = decision_map
#' )
#'
#' # Step 3: Run multiverse analysis
#' results <- run_multiverse_analysis(
#'   data = validated_data,
#'   specifications = specs$specifications,
#'   verbose = TRUE,
#'   progress = TRUE
#' )
#'
#' # Step 4: Examine results
#' summary(results)
#' head(results$results)
#' }
#'
#' @seealso
#' \code{\link{check_data_multiverse}} for data validation,
#' \code{\link{create_principled_multiverse_specifications}} for creating specifications,
#' \code{\link{general_multiverse}} for the core analysis function
#'
#' @export
run_multiverse_analysis <- function(data, specifications, verbose = FALSE, progress = TRUE) {

  # Input validation
  if (!inherits(data, "data.frame")) {
    stop("'data' must be a data frame")
  }
  if (!inherits(specifications, "data.frame")) {
    stop("'specifications' must be a data frame")
  }
  if (nrow(specifications) == 0) {
    stop("'specifications' cannot be empty")
  }

  # Check for data validation
  if (is.null(attr(data, "multiverse_validated"))) {
    warning("Data appears unvalidated. Consider running check_data_multiverse() first.")
  }

  # Initialize tracking variables
  multiverse_warnings <- character(0)
  n_specs <- nrow(specifications)

  if (verbose) {
    cat("🚀 Starting multiverse analysis...\n")
    cat("   📊 Dataset:", nrow(data), "effect sizes from",
        length(unique(data$study)), "studies\n")
    cat("   🔬 Specifications:", n_specs, "unique analyses to run\n")
    cat("   🎯 Multiverse groups:", length(unique(specifications$multiverse_id)), "\n\n")
  }

  # Initialize progress bar
  if (progress) {
    pb <- txtProgressBar(min = 0, max = n_specs, style = 3, width = 60, char = "█")
  }

  # Main analysis loop
  results <- lapply(seq_len(n_specs), function(i) {
    # Update progress bar
    if (progress) {
      setTxtProgressBar(pb, i)
    }

    # Run individual specification with error handling
    tryCatch({
      withCallingHandlers({
        general_multiverse(i, data, specifications)
      },
      warning = function(w) {
        multiverse_warnings <<- c(
          multiverse_warnings,
          paste0("Spec ", i, ": ", w$message)
        )
        invokeRestart("muffleWarning")
      })
    },
    error = function(e) {
      multiverse_warnings <<- c(
        multiverse_warnings,
        paste0("Spec ", i, " FAILED: ", e$message)
      )
      if (verbose) {
        cat("\n⚠️  Specification", i, "failed:", e$message, "\n")
      }
      NULL
    })
  })

  # Clean up progress bar
  if (progress) {
    close(pb)
    if (verbose) cat("\n")
  }

  # Process results
  results <- results[!sapply(results, is.null)]

  if (length(results) == 0) {
    warning("No specifications completed successfully. Check your data and specifications.")
    result <- structure(
      list(
        results = NULL,
        multiverse_warnings = multiverse_warnings,
        n_warnings = length(multiverse_warnings),
        n_attempted = n_specs,
        n_successful = 0
      ),
      class = "multiverse_result"
    )
    return(result)
  }

  # Combine all successful results
  if (verbose) cat("📋 Combining results from", length(results), "successful analyses...\n")

  final_results <- do.call(rbind, results)

  # Add derived variables
  final_results$full_set <- as.numeric(
    final_results$set == paste(seq_len(nrow(data)), collapse = ",")
  )

  # Data cleaning
  # Remove rows with missing core results (but allow missing p-values for Bayesian methods)
  core_vars <- c("b", "ci.lb", "ci.ub", "k", "set")
  n_before_cleaning <- nrow(final_results)
  final_results <- final_results[complete.cases(final_results[, core_vars]), ]
  n_after_cleaning <- nrow(final_results)

  if (n_before_cleaning > n_after_cleaning && verbose) {
    cat("🧹 Removed", n_before_cleaning - n_after_cleaning, "rows with missing core results\n")
  }

  # Remove duplicates (same estimate, study set, and method)
  duplicate_key <- c("b", "set", "ma_method", "dependency")
  n_before_dedup <- nrow(final_results)
  final_results <- final_results[!duplicated(final_results[, duplicate_key]), ]
  n_after_dedup <- nrow(final_results)

  if (n_before_dedup > n_after_dedup && verbose) {
    cat("🔄 Removed", n_before_dedup - n_after_dedup, "duplicate analyses\n")
  }

  # Create result object
  result <- structure(
    list(
      results = final_results,
      multiverse_warnings = multiverse_warnings,
      n_warnings = length(multiverse_warnings),
      n_attempted = n_specs,
      n_successful = length(results),
      n_final = nrow(final_results)
    ),
    class = "multiverse_result"
  )

  # Summary output
  if (verbose) {
    cat("\n✅ Multiverse analysis completed!\n")
    cat("   📈 Results:", nrow(final_results), "unique meta-analyses\n")
    cat("   ⚠️  Warnings:", length(multiverse_warnings), "\n")
    cat("   📊 Success rate:", round(100 * length(results) / n_specs, 1), "%\n")

    if (length(multiverse_warnings) > 0) {
      cat("\n💡 Access warnings with: result$multiverse_warnings\n")
    }
  }

  return(result)
}
