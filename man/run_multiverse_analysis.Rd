% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/run_multiverse_analysis.R
\name{run_multiverse_analysis}
\alias{run_multiverse_analysis}
\title{Run Multiverse Meta-Analysis}
\usage{
run_multiverse_analysis(data, specifications, verbose = FALSE, progress = TRUE)
}
\arguments{
\item{data}{A validated data frame containing the meta-analysis dataset.
Must be previously validated using \code{\link{check_data_multiverse}}.
Required columns: \code{study}, \code{es_id}, \code{yi}, \code{vi}, plus any
"Which factor" columns (e.g., \code{wf_1}, \code{wf_2}).}

\item{specifications}{A data frame of analysis specifications generated by
\code{\link{create_principled_multiverse_specifications}}. Each row represents
one unique combination of Which factors, dependency handling, and meta-analytic method.}

\item{verbose}{Logical. If \code{TRUE}, prints detailed progress information
and a summary of warnings at completion (default: \code{FALSE}).}

\item{progress}{Logical. If \code{TRUE}, displays a progress bar during execution
(default: \code{TRUE}).}
}
\value{
An object of class \code{"multiverse_result"} containing:
\describe{
  \item{\code{results}}{A data frame with one row per successful analysis, including:
    \itemize{
      \item \code{b}: Effect size estimate
      \item \code{ci.lb}, \code{ci.ub}: 95% confidence interval bounds
      \item \code{pval}: P-value (NA for Bayesian methods)
      \item \code{k}: Number of studies included in the analysis
      \item \code{set}: Character string listing the study IDs included
      \item \code{full_set}: Binary indicator (1 = all studies included, 0 = subset)
      \item All "Which factor" columns from specifications
      \item \code{dependency}: Dependency handling method used
      \item \code{ma_method}: Meta-analytic method used
      \item \code{multiverse_id}: Groups specifications into separate multiverse analyses
    }
  }
  \item{\code{multiverse_warnings}}{Character vector of all warnings encountered}
  \item{\code{n_warnings}}{Integer count of total warnings}
}
}
\description{
Executes a comprehensive multiverse meta-analysis across all specifications,
applying different combinations of study selection criteria ("Which" factors),
meta-analytic methods, and dependency handling strategies.
}
\section{Workflow Overview}{

The function executes the following steps:
\enumerate{
  \item \bold{Iterate through specifications}: Each row in \code{specifications}
        defines one unique analysis to perform
  \item \bold{Apply Which factors}: Filter studies based on specified criteria
        (e.g., only studies with certain populations, measures, etc.)
  \item \bold{Handle dependencies}: Apply appropriate dependency handling:
        \itemize{
          \item \code{"aggregate"}: Pool multiple effect sizes per study using
                composite correlation structure
          \item \code{"select_max"}/\code{"select_min"}: Select one effect size
                per study based on magnitude
          \item \code{"modeled"}: Use multilevel models (3-level, RVE) to
                explicitly model dependency structure
        }
  \item \bold{Apply meta-analytic method}: Execute the specified estimator
        (FE, REML, bias-correction methods, etc.)
  \item \bold{Combine and clean results}: Merge all successful analyses,
        remove duplicates, and add summary indicators
}
}

\section{Error Handling}{

The function is designed to be robust:
\itemize{
  \item Individual specification failures don't stop the entire analysis
  \item Warnings are captured and can be reviewed post-analysis
  \item Invalid combinations (e.g., wrong dependency for a method) return \code{universe_NA}
  \item Progress tracking helps identify where issues occur
}
}

\section{Performance Considerations}{

For large multiverse analyses:
\itemize{
  \item Consider setting \code{progress = FALSE} for cleaner output in scripts
  \item The function uses vectorized operations where possible
  \item Memory usage scales with the number of successful specifications
  \item Use \code{options(metaMultiverse.skip_slow = TRUE)} to exclude
        computationally intensive methods like Bayesian estimators
}
}

\examples{
\dontrun{
# Step 1: Prepare and validate data
data <- data.frame(
  study = rep(paste0("Study_", 1:8), each = 2),
  es_id = 1:16,
  yi = rnorm(16, mean = 0.3, sd = 0.4),
  vi = runif(16, min = 0.01, max = 0.05),
  wf_population = rep(c("adults", "children"), times = 8),
  wf_measure = rep(c("self-report", "behavioral"), each = 8)
)
validated_data <- check_data_multiverse(data)

# Step 2: Create specifications
decision_map <- c("wf_population" = "E", "wf_measure" = "U")
specs <- create_principled_multiverse_specifications(
  data = validated_data,
  wf_vars = c("wf_population", "wf_measure"),
  ma_methods = c("fe", "reml", "pet-peese"),
  dependencies = c("aggregate", "select_max"),
  decision_map = decision_map
)

# Step 3: Run multiverse analysis
results <- run_multiverse_analysis(
  data = validated_data,
  specifications = specs$specifications,
  verbose = TRUE,
  progress = TRUE
)

# Step 4: Examine results
summary(results)
head(results$results)
}

}
\seealso{
\code{\link{check_data_multiverse}} for data validation,
\code{\link{create_principled_multiverse_specifications}} for creating specifications,
\code{\link{general_multiverse}} for the core analysis function
}
