---
title: "Multiverse Meta-Analysis with metaMultiverse"
author: "Constantin Yves Plessen"
date: "`r Sys.Date()`"
execute:
  cache: true
  warning: false  # Optional: suppress warnings
  message: false  # Optional: suppress messages
format:
  html:
    minimal: true
    theme: none  # Use our custom CSS instead
    css: modern-styles.css
    toc: true
    toc-location: left
    code-fold: true
    code-tools: true
vignette: >
  %\VignetteIndexEntry{Multiverse Meta-Analysis with metaMultiverse}
  %\VignetteEngine{quarto::html}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  warning = FALSE,
  message = FALSE,
  comment = "#>",
  fig.width = 8,
  fig.height = 6,
  fig.retina = 2,
  out.width = "100%"
)
```

## Introduction to Multiverse Meta-Analysis {.unnumbered}

Multiverse meta-analysis is an approach that addresses the analytical flexibility inherent in meta-analysis by exploring multiple reasonable analytical choices simultaneously. This package provides tools for conducting multiverse pairwise meta-analyses with standardized mean differences.

::: {.callout-note}
## What is a multiverse analysis?

A multiverse analysis considers all reasonable analytical choices simultaneously, rather than committing to a single analytical path. This approach acknowledges the potential impact of researcher decisions on results and provides a more complete picture of possible outcomes.
:::

### Package Philosophy

The `metaMultiverse` package is designed to:

1. Enable exploration of different meta-analytic choices ("which" factors and "how" factors)
2. Visualize the impact of these choices on effect size estimates
3. Assess the robustness of conclusions across the multiverse of possible analyses

## Installation {#installation}

You can install the development version of `metaMultiverse` from GitHub:

```{r installation, eval=FALSE}
# install.packages("devtools")
devtools::install_github("cyplessen/metaMultiverse")
```

## Workflow Overview {#workflow}

The typical workflow for a multiverse meta-analysis using this package consists of four main steps:


### 1. Data Preparation
Prepare and validate your dataset to ensure it meets the requirements for multiverse analysis.

### 2. Create Specifications
Define the analytical choices to explore, including "which" factors (data subsets) and "how" factors (meta-analytic methods).

### 3. Run Analysis
Apply specifications to create a multiverse of meta-analyses, exploring all reasonable analytical paths.

### 4. Visualize Results
Explore the results through specification curves and other visualizations to assess robustness.


This tutorial walks through each step with a practical example.

### Example Dataset

For this tutorial, we'll use a dataset of digital depression interventions:

```{r load-data}
# Load required packages
library(metaMultiverse)
library(tidyr)
library(dplyr) # data wrangling
library(ggplot2) # data visualization
library(plotly) # interactive data visualization
library(kableExtra) # data formatting

# Load example dataset
data("data_digDep") 

# Examine the structure
data_digDep %>%
  kable(format = "html") %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"),
    full_width = FALSE,
    position = "center"
  ) %>%
  scroll_box(width = "100%", height = "300px")
```

## Step 1: Data Validation {#step1}

Before proceeding with a multiverse meta-analysis, it's important to ensure your data meets the requirements:

```{r validate-data}
# Check if data meets requirements for multiverse analysis
check_data_multiverse(data_digDep)
```

::: {.callout-tip}
## What the validator checks
The `check_data_multiverse()` function validates:

- Required columns are present (`study`, `es_id`, `yi`, `vi`, and `wf_*` columns)
- Columns have correct data types
- Effect size IDs are unique
- No critical missing values
:::

## Step 2: Create Specifications {#step2}

Next, we define the specifications to explore in our multiverse analysis:

```{r create-specs}
# Define "Which factors" (analytical choices about data subsets)
wf_vars <- c("wf_1", "wf_2", "wf_3", "wf_4")

# Define meta-analytical methods
ma_methods <- c("reml", "fe", "3-level", "rve", "p-uniform")

# Define dependency handling approaches
dependencies <- c("aggregate", "modeled")

# Create specifications grid
specs <- create_multiverse_specifications(
  data = data_digDep,
  wf_vars = wf_vars,
  ma_methods = ma_methods,
  dependencies = dependencies
)

# Display number of specifications
tibble(
  "Description" = "Number of valid specifications",
  "Value" = specs$number_specs
) %>%
  kable(format = "html") %>%
  kable_styling(full_width = FALSE, position = "left")

# Look at first few specifications
specs$specifications %>%
  head(10) %>% 
  kable(format = "html") %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed"),
    full_width = FALSE
  ) %>%
  column_spec(1:ncol(specs$specifications), 
              background = if_else(
                grepl("total_", as.matrix(specs$specifications[1:10,])), 
                "#e8f4f8", "white"
              ))
```

::: {.callout-important}
## Understanding specifications
Each row in the specifications represents a unique analytical path through the multiverse. The columns indicate:

- Which data subsets to use (which factors, `wf_*` columns)
- How to handle dependencies between effect sizes (`dependency`)
- Which meta-analytical method to apply (`ma_method`)
:::

## Step 3: Run Multiverse Analysis {#step3}

With our specifications defined, we can now run the multiverse analysis:

```{r run-multiverse}
#| warning: false

# Run the multiverse analysis
results <- run_multiverse_analysis(
  data_multiverse = data_digDep,
  specifications = specs$specifications,
  how_methods = ma_methods
)

# View summary of results
summary_stats <- results %>%
  summarize(
    n_analyses = n(),
    mean_es = mean(b, na.rm = TRUE),
    median_es = median(b, na.rm = TRUE),
    min_es = min(b, na.rm = TRUE),
    max_es = max(b, na.rm = TRUE),
    prop_significant = mean(pval < 0.05, na.rm = TRUE)
  )

summary_stats %>%
  tidyr::pivot_longer(cols = everything(), names_to = "Statistic", values_to = "Value") %>%
  mutate(
    Value = case_when(
      Statistic == "prop_significant" ~ paste0(round(Value * 100, 1), "%"),
      TRUE ~ round(Value, 3) %>% as.character()
    ),
    Statistic = case_when(
      Statistic == "n_analyses" ~ "Number of Analyses",
      Statistic == "mean_es" ~ "Mean Effect Size",
      Statistic == "median_es" ~ "Median Effect Size",
      Statistic == "min_es" ~ "Minimum Effect Size",
      Statistic == "max_es" ~ "Maximum Effect Size",
      Statistic == "prop_significant" ~ "Proportion Significant (p < 0.05)",
      TRUE ~ Statistic
    )
  ) %>%
  kable(format = "html", caption = "Summary of Multiverse Meta-Analysis Results") %>%
  kable_styling(
    bootstrap_options = c("striped", "hover"),
    full_width = FALSE,
    position = "center"
  ) %>%
  row_spec(row = 0, bold = TRUE, color = "white", background = "#2c3e50")
```

## Step 4: Visualize Results {#step4}

The `metaMultiverse` package provides several visualization options to explore and interpret your results.

### Specification Curve {#spec-curve}

The specification curve visualizes the distribution of effect sizes across all specifications:

```{r fig.width=10, fig.height=8}
#| label: fig-spec-curve
#| fig-cap: "Specification curve showing the distribution of effect sizes across all analytical choices."

# Define a lookup table for factor labels
factor_label_lookup <- list(
  wf_1 = "Technology Type",
  wf_2 = "Guidance Level",
  wf_3 = "Target Group",
  wf_4 = "Therapy Type",
  ma_method = "Meta-Analysis Method"
)

# Create the specification curve plot
plotly_descriptive_spec_curve(
  data = results,
  ylim_lower = -0.5,
  ylim_upper = 1.5,
  colorblind_friendly = TRUE,
  factor_label_lookup = factor_label_lookup
)
```

The specification curve consists of two panels:

1. **Top panel**: Shows the effect size estimates with confidence intervals, ordered by effect size magnitude
2. **Bottom panel**: Shows which analytical choices were made for each specification

### Vibration of Effects Plot {#voe-plot}

The Vibration of Effects plot shows the relationship between effect sizes and p-values:

```{r fig.width=8, fig.height=6}
#| label: fig-voe
#| fig-cap: "Vibration of Effects plot showing relationship between effect sizes and p-values."

plotly_VoE(
  data = results,
  x = "b",
  y = "pval",
  colorblind_friendly = TRUE,
  cutoff = 5,  # Minimum number of studies
  vertical_lines = c(0.1, 0.9),  # Quantile reference lines
  hline_value = 0.05  # Significance threshold
)
```

::: {.callout-note}
## Interpreting the Vibration of Effects plot
- Points represent individual meta-analyses
- Color intensity represents point density
- Horizontal line: conventional significance threshold (p = 0.05)
- Vertical lines: effect size distribution quantiles (10th and 90th percentiles)
:::

## Interpreting Multiverse Results {#interpretation}

When interpreting results from a multiverse meta-analysis, consider:


### Consistency
**Consistency of direction**: Do most specifications suggest effects in the same direction?

A finding is more robust if the majority of specifications point to effects in the same direction, even if magnitude varies.

### Range
**Range of effect sizes**: How much do effect sizes vary across specifications?

A narrow range suggests conclusions are stable across analytical choices, while wide ranges indicate high sensitivity to analytical decisions.

### Decision Impact
**Analytical decisions driving variation**: Which analytical choices have the largest impact on results?

Identify which factors (e.g., inclusion criteria, meta-analytical method) most strongly influence effect size estimates.

### Significance
**Proportion of significant results**: What proportion of specifications yield statistically significant results?

A high proportion of significant results across the multiverse suggests a robust finding.

### Sensitivity
**Decision sensitivity**: Are conclusions robust to different analytical choices?

Assess whether key conclusions change substantively depending on analytical choices.

## Advanced Usage {#advanced}

### Custom Meta-Analytical Methods {#custom-methods}

You can extend the package by adding custom meta-analytical methods:

```{r custom-method, eval=FALSE}
# Example of defining a custom meta-analytical function
calculate_custom_method <- function(dat) {
  # Your custom implementation here
  
  # Return results in standardized format
  list(
    b = estimate,
    ci.lb = lower_ci,
    ci.ub = upper_ci,
    pval = p_value
  )
}

# Add to how_methods
custom_methods <- c(ma_methods, "custom_method")
```

### Subset Analysis {#subset-analysis}

You can focus on a subset of specifications for targeted analysis:

```{r subset-analysis, eval=FALSE}
# Focus on specifications with specific characteristics
subset_specs <- specs$specifications %>%
  filter(
    wf_1 == "specific_value",
    dependency == "modeled"
  )

# Run analysis on subset
#subset_results <- run_multiverse_analysis(
#  data_multiverse = data_digDep,
#  specifications = subset_specs,
#  how_methods = ma_methods
#)
```

## Conclusion {#conclusion}

The `metaMultiverse` package provides a systematic framework for exploring the impact of analytical decisions in meta-analysis. By conducting and visualizing multiple analyses simultaneously, researchers can:

1. Identify which analytical choices significantly impact conclusions
2. Present more transparent and robust meta-analytic results
3. Better understand the sensitivity of findings to methodological decisions

::: {.callout-tip}
## Best practices for multiverse meta-analysis
- Pre-register your multiverse analysis plan when possible
- Clearly document all analytical choices
- Report the full range of results rather than cherry-picking
- Consider theoretical justifications for different analytical choices
- Use visualizations to communicate the multiverse of results effectively
:::

For more information, see the package documentation or contact the developers.

