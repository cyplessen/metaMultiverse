---
title: "Multiverse Meta-Analysis with metaMultiverse"
author: "Constantin Yves Plessen"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    code_folding: show
    theme: flatly
    highlight: tango
vignette: >
  %\VignetteIndexEntry{Multiverse Meta-Analysis with metaMultiverse}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  warning = FALSE,
  message = FALSE,
  comment = "#>",
  fig.width = 8,
  fig.height = 6,
  fig.retina = 2,
  out.width = "100%"
)
```

## Introduction to Multiverse Meta-Analysis

Multiverse meta-analysis is an approach that addresses the analytical flexibility inherent in meta-analysis by exploring multiple reasonable analytical choices simultaneously. This package provides tools for conducting multiverse pairwise meta-analyses with standardized mean differences.

> **What is a multiverse analysis?**
> 
> A multiverse analysis considers all reasonable analytical choices simultaneously, rather than committing to a single analytical path. This approach acknowledges the potential impact of researcher decisions on results and provides a more complete picture of possible outcomes.

### Package Philosophy

The `metaMultiverse` package is designed to:

1. **User-friendly factor definitions**: Use intuitive, researcher-friendly terminology instead of generic `wf_*` column names
2. **Custom factor groupings**: Support sophisticated groupings like "low_risk_only", "exclude_high_risk", and "all_studies"
3. **Principled decision types**: Distinguish between equivalent (E), uncertain (U), and non-equivalent (N) analytical choices
4. **Robust visualization**: Assess the impact of analytical choices on effect size estimates

## Installation

You can install the development version of `metaMultiverse` from GitHub:

```{r installation, eval=FALSE}
# install.packages("devtools")
#devtools::install_github("cyplessen/metaMultiverse")
devtools::load_all()
```

## Enhanced Workflow Overview

The enhanced workflow for multiverse meta-analysis consists of four main steps, now with user-friendly factor definitions and custom groupings:

### 1. Data Preparation with User-Friendly Names
Prepare your dataset with meaningful column names that researchers actually use.

### 2. Define Factors with Custom Groupings
Use the new `define_factors()` function to create sophisticated factor groupings with clear decision types.

### 3. Create Principled Specifications
Generate specifications that respect the logical structure of your analytical choices.

### 4. Run Analysis and Visualize Results
Execute the multiverse analysis and explore results through comprehensive visualizations.

This tutorial walks through each step with a practical example using digital depression intervention data.

## Example Dataset

For this tutorial, we'll use a dataset of digital depression interventions with user-friendly column names:

```{r load-data}
# Load required packages
library(metaMultiverse)
library(dplyr)
library(ggplot2)
library(kableExtra)

# Load example dataset
data("data_digDep") 

# Helper function to create user-friendly column names
create_user_friendly_digDep <- function(data_digDep) {
  # Create a copy and rename the wf_* columns to meaningful names
  user_data <- data_digDep
  
  # Rename wf_* columns to what researchers would actually call them
  names(user_data)[names(user_data) == "wf_1"] <- "technology_type"      # website, mobile, etc.
  names(user_data)[names(user_data) == "wf_2"] <- "guidance_level"       # guided, minimal support, etc.
  names(user_data)[names(user_data) == "wf_3"] <- "population"           # adult, etc.
  names(user_data)[names(user_data) == "wf_4"] <- "therapy_approach"     # cbt-based, not-cbt-based, etc.
  names(user_data)[names(user_data) == "wf_5"] <- "control_type"         # waitlist, other control
  names(user_data)[names(user_data) == "wf_6"] <- "diagnostic_status"    # clinical cutoff, etc.
  names(user_data)[names(user_data) == "wf_7"] <- "risk_of_bias"         # some concerns, high risk, etc.
  names(user_data)[names(user_data) == "wf_8"] <- "time_point"           # post-treatment, follow-up
  
  return(user_data)
}

# Create user-friendly dataset
depression_data <- create_user_friendly_digDep(data_digDep)

# Examine the structure with meaningful names
depression_data %>%
  select(study, es_id, yi, vi, technology_type, guidance_level, population, 
         therapy_approach, risk_of_bias) %>%
  head(10) %>%
  kable(format = "html", caption = "Digital Depression Interventions Dataset") %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed", "responsive"),
    full_width = FALSE,
    position = "center"
  ) %>%
  scroll_box(width = "100%", height = "300px")
```

## Step 1: Data Validation

Before proceeding with multiverse analysis, validate your data to ensure it meets requirements:

```{r validate-data}
# Check if data meets requirements for multiverse analysis
depression_data_validated <- check_data_multiverse(depression_data)
```

> **What the validator checks**
> 
> The `check_data_multiverse()` function validates:
> - Required columns are present (`study`, `es_id`, `yi`, `vi`, and factor columns)
> - Columns have correct data types
> - Effect size IDs are unique
> - No critical missing values
> - Reasonable effect size and variance values

## Step 2: Define Factors with Custom Groupings

The new `define_factors()` function allows you to create sophisticated factor groupings using researcher-friendly terminology:

```{r define-factors}
# Define factors with custom groups and decision types
setup <- define_factors(
  depression_data_validated,
  
  # Risk of bias with custom hierarchical groupings
  Risk_of_Bias = list("risk_of_bias", 
                      decision = "U",  # Uncertain which inclusion criteria is best
                      groups = list(
                        "low_risk_only" = "low risk",
                        "exclude_high_risk" = c("low risk", "some concerns"), 
                        "all_studies" = c("low risk", "some concerns", "high risk")
                      )
  ),
  
  # Technology type with standard multiverse (each level + total)
  Technology = list("technology_type", 
                    decision = "U",    # Uncertain which technology is best
                    type = "binary"),  # Each level individually + all combined
  
  # Population as equivalent levels (standard multiverse)
  Population = "population|E",  # Equivalent - creates multiverse options
  
  # Therapy approach as separate analyses
  Therapy_Approach = "therapy_approach|N"  # Non-equivalent - separate analyses
)

# The setup object contains everything we need
names(setup)
```

> **Understanding Decision Types**
> 
> - **U (Uncertain)**: "Which inclusion criteria should I use?" â†’ creates multiverse options
> - **E (Equivalent)**: "These measure the same thing" â†’ creates multiverse options  
> - **N (Non-equivalent)**: "These are different research questions" â†’ separate analyses

## Step 3: Create Principled Specifications

Now we create specifications that respect the logical structure of our analytical choices:

```{r create-specs}
# Define meta-analytical methods and dependency handling
ma_methods <- c("reml", "fe", "pet-peese")
dependencies <- c("aggregate")

# Create specifications with custom groups
custom_specs <- create_principled_multiverse_specifications(
  data = setup$data,  # Use setup$data which has the wf_* columns
  wf_vars = setup$factors$wf_internal,  # Use the internal wf_* names
  ma_methods = ma_methods,
  dependencies = dependencies,
  decision_map = setup$decision_map,
  factor_groups = setup$factor_groups   # Pass the custom groups
)

# Display summary information
cat("ðŸ“Š Specification Summary:\n")
cat("   â€¢ Total specifications:", custom_specs$number_specs, "\n")
cat("   â€¢ Unique multiverses:", length(unique(custom_specs$specifications$multiverse_id)), "\n")
cat("   â€¢ Methods:", paste(ma_methods, collapse = ", "), "\n")
cat("   â€¢ Custom factor groups:", length(setup$factor_groups), "\n")

# Look at first few specifications
custom_specs$specifications %>%
  head(10) %>% 
  kable(format = "html", caption = "First 10 Specifications") %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed"),
    full_width = FALSE
  )
```

> **Understanding Custom Groups**
> 
> Each row in the specifications represents a unique analytical path through the multiverse. Custom groups like "exclude_high_risk" automatically map to the appropriate data levels (e.g., c("low risk", "some concerns")) during analysis.

## Step 4: Run Multiverse Analysis

With our specifications defined, we can now run the comprehensive multiverse analysis:

```{r run-multiverse}
#| warning: false

# Run the multiverse analysis
results <- run_multiverse_analysis(
  data = setup$data,  # Use setup$data which has the wf_* columns
  specifications = custom_specs$specifications,
  factor_groups = setup$factor_groups,  # Pass custom groups for filtering
  verbose = TRUE,
  progress = TRUE
)

# View summary of results
summary_stats <- results$results %>%
  summarize(
    n_analyses = n(),
    mean_es = mean(b, na.rm = TRUE),
    median_es = median(b, na.rm = TRUE),
    min_es = min(b, na.rm = TRUE),
    max_es = max(b, na.rm = TRUE),
    prop_significant = mean(pval < 0.05, na.rm = TRUE),
    n_multiverses = length(unique(multiverse_id))
  )

summary_stats %>%
  tidyr::pivot_longer(cols = everything(), names_to = "Statistic", values_to = "Value") %>%
  mutate(
    Value = case_when(
      Statistic == "prop_significant" ~ paste0(round(Value * 100, 1), "%"),
      Statistic %in% c("n_analyses", "n_multiverses") ~ as.character(Value),
      TRUE ~ round(Value, 3) %>% as.character()
    ),
    Statistic = case_when(
      Statistic == "n_analyses" ~ "Number of Analyses",
      Statistic == "mean_es" ~ "Mean Effect Size",
      Statistic == "median_es" ~ "Median Effect Size", 
      Statistic == "min_es" ~ "Minimum Effect Size",
      Statistic == "max_es" ~ "Maximum Effect Size",
      Statistic == "prop_significant" ~ "Proportion Significant (p < 0.05)",
      Statistic == "n_multiverses" ~ "Number of Separate Multiverses",
      TRUE ~ Statistic
    )
  ) %>%
  kable(format = "html", caption = "Summary of Multiverse Meta-Analysis Results") %>%
  kable_styling(
    bootstrap_options = c("striped", "hover"),
    full_width = FALSE,
    position = "center"
  ) %>%
  row_spec(row = 0, bold = TRUE, color = "white", background = "#2c3e50")
```

## Step 5: Visualize Results

The `metaMultiverse` package provides several visualization options to explore and interpret your results.

### Specification Curve

The specification curve visualizes the distribution of effect sizes across all specifications:

```{r fig.width=10, fig.height=8}
#| label: fig-spec-curve
#| fig-cap: "Specification curve showing the distribution of effect sizes across all analytical choices with custom factor groupings."

# Create a lookup table for factor labels that maps to our user-friendly names
factor_label_lookup <- list(
  wf_1 = "Risk of Bias",
  wf_2 = "Technology Type", 
  wf_3 = "Population",
  wf_4 = "Therapy Approach",
  ma_method = "Meta-Analysis Method",
  dependency = "Dependency Handling"
)

# Create the specification curve plot
plotly_descriptive_spec_curve(
  data = results$results,
  ylim_lower = -0.5,
  ylim_upper = 1.5,
  colorblind_friendly = TRUE,
  factor_label_lookup = factor_label_lookup
)
```

The specification curve consists of two panels:

1. **Top panel**: Shows the effect size estimates with confidence intervals, ordered by effect size magnitude
2. **Bottom panel**: Shows which analytical choices were made for each specification, including custom groupings

> **Interpreting Custom Groupings**
> 
> Notice how the bottom panel shows your custom group names (like "exclude_high_risk", "all_studies") rather than raw data levels. This makes it much easier to understand which inclusion criteria were applied in each analysis.

### Effect Size Distribution by Custom Groups

Let's examine how our custom risk of bias groupings affect the results:

```{r custom-groups-analysis}
# Analyze results by custom risk of bias groups
risk_bias_summary <- results$results %>%
  filter(!is.na(wf_1)) %>%  # wf_1 corresponds to Risk_of_Bias
  group_by(wf_1) %>%
  summarise(
    n_analyses = n(),
    mean_effect = mean(b, na.rm = TRUE),
    median_effect = median(b, na.rm = TRUE),
    prop_significant = mean(pval < 0.05, na.rm = TRUE),
    .groups = 'drop'
  ) %>%
  arrange(desc(mean_effect))

risk_bias_summary %>%
  kable(format = "html", 
        caption = "Effect Sizes by Risk of Bias Grouping",
        col.names = c("Risk of Bias Group", "N Analyses", "Mean Effect", 
                      "Median Effect", "Prop. Significant")) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```

### Vibration of Effects Plot

The Vibration of Effects plot shows the relationship between effect sizes and p-values:

```{r fig.width=8, fig.height=6}
#| label: fig-voe
#| fig-cap: "Vibration of Effects plot showing relationship between effect sizes and p-values across custom factor groupings."

plotly_VoE(
  data = results$results,
  x = "b",
  y = "pval",
  colorblind_friendly = TRUE,
  cutoff = 5,  # Minimum number of studies
  vertical_lines = c(0.1, 0.9),  # Quantile reference lines
  hline_value = 0.05  # Significance threshold
)
```

> **Interpreting the Vibration of Effects plot**
> 
> - Points represent individual meta-analyses from your multiverse
> - Color intensity represents point density
> - Horizontal line: conventional significance threshold (p = 0.05)
> - Vertical lines: effect size distribution quantiles (10th and 90th percentiles)

### Comparing Multiverse Results

Since we used "N" (Non-equivalent) decision type for therapy approach, we have separate multiverse analyses:

```{r multiverse-comparison}
# Compare results across different therapy approaches (separate multiverses)
multiverse_comparison <- results$results %>%
  group_by(multiverse_id) %>%
  summarise(
    n_analyses = n(),
    mean_effect = mean(b, na.rm = TRUE),
    median_effect = median(b, na.rm = TRUE),
    range_effect = max(b, na.rm = TRUE) - min(b, na.rm = TRUE),
    prop_significant = mean(pval < 0.05, na.rm = TRUE),
    .groups = 'drop'
  )

multiverse_comparison %>%
  kable(format = "html", 
        caption = "Comparison Across Separate Multiverse Analyses",
        col.names = c("Multiverse", "N Analyses", "Mean Effect", 
                      "Median Effect", "Effect Range", "Prop. Significant")) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)
```

## Interpreting Enhanced Multiverse Results

When interpreting results from the enhanced multiverse meta-analysis with custom factor groupings:

### 1. **Custom Group Impact**
**Hierarchical inclusion criteria**: How do different risk of bias thresholds affect conclusions?

Our custom groupings ("low_risk_only", "exclude_high_risk", "all_studies") allow us to systematically examine how inclusion criteria affect results.

### 2. **Decision Type Effects**
**Analytical structure**: How do different decision types shape the analysis?

- **U (Uncertain)** factors create multiverse options within each analysis
- **E (Equivalent)** factors create multiverse options (similar to U)
- **N (Non-equivalent)** factors create entirely separate analyses

### 3. **Range of Robustness**
**Effect stability**: How consistent are effects across custom groupings?

A narrow range of effects across sophisticated groupings suggests robust findings, while wide ranges indicate sensitivity to inclusion criteria.

## Advanced Usage with Custom Groupings

### Ordered Factor Groupings

You can create cumulative groupings for ordered factors:

```{r ordered-example, eval=FALSE}
# Example of ordered risk assessment
setup_ordered <- define_factors(
  data,
  Study_Quality = list("quality_rating",
                       type = "ordered",
                       decision = "U",
                       levels = c("high", "medium", "low"))
)
# This creates: "up_to_high", "up_to_medium", "up_to_low" groupings
```

### Complex Custom Groupings

You can create sophisticated inclusion criteria:

```{r complex-example, eval=FALSE}
setup_complex <- define_factors(
  data,
  
  # Complex intervention groupings
  Intervention_Intensity = list("intervention_type",
                                decision = "U",
                                groups = list(
                                  "minimal" = c("self_help", "bibliotherapy"),
                                  "moderate" = c("self_help", "bibliotherapy", "guided_self_help"),
                                  "intensive" = c("guided_self_help", "therapist_delivered"),
                                  "all_types" = c("self_help", "bibliotherapy", "guided_self_help", "therapist_delivered")
                                )),
  
  # Population-based groupings
  Target_Population = list("population_type",
                           decision = "N",  # Separate analyses for different populations
                           groups = list(
                             "clinical_only" = "clinical_diagnosis",
                             "subclinical_and_clinical" = c("subclinical", "clinical_diagnosis"),
                             "prevention_focus" = c("at_risk", "general_population")
                           ))
)
```

## Best Practices for Enhanced Multiverse Analysis

### 1. **Meaningful Groupings**
- Design custom groups that reflect real research decisions
- Use hierarchical groupings (restrictive â†’ permissive) when appropriate
- Ensure group names are self-explanatory

### 2. **Appropriate Decision Types**
- Use **U** when you're uncertain which criteria are best
- Use **E** when criteria are theoretically equivalent
- Use **N** when criteria represent fundamentally different research questions

### 3. **Transparent Reporting**
- Document the rationale for each custom grouping
- Report the full range of results across groupings
- Highlight which groupings drive the most variation

### 4. **Validation**
- Test your custom groupings with sensitivity analyses
- Ensure groupings align with domain expertise
- Consider pre-registering your grouping strategy

## Conclusion

The enhanced `metaMultiverse` package provides a sophisticated framework for exploring analytical decisions in meta-analysis through:

1. **User-friendly factor definitions** that use meaningful terminology
2. **Custom factor groupings** that capture complex inclusion criteria
3. **Principled decision types** that structure the analytical space appropriately
4. **Comprehensive visualizations** that communicate results effectively

By conducting and visualizing multiple analyses simultaneously with sophisticated groupings, researchers can:

- Identify which inclusion criteria significantly impact conclusions
- Present more transparent and robust meta-analytic results  
- Better understand the sensitivity of findings to methodological decisions
- Communicate uncertainty more effectively to stakeholders

> **Best practices for enhanced multiverse meta-analysis**
> 
> - Pre-register your custom grouping strategy when possible
> - Design groupings that reflect genuine research decisions
> - Use appropriate decision types (E/U/N) for your factors
> - Report the full range of results rather than cherry-picking
> - Use visualizations to communicate the multiverse of results effectively

For more information, see the package documentation or contact the developers.

## Session Information

```{r session-info}
sessionInfo()
```
